{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "¿Qué es pytorch?\n",
    "\n",
    "Pytorch es una biblioteca cuyo principal objetvio es agilizar las operaciones que vemos comunmente en Numpy. Esto lo logra ya que en un programa normal de Numpy este se ejecuta en su totalidad en el CPU de nuestra computadora, pytorch busca agilizar el calculo de varias operaciones usando CUDA cores, el cual es un tipo de arquitecttura implementado en las por la compañia Nvidia en su linea de tarjetas graficas o GPU's\n",
    "\n",
    "¿Tiene sentido usar Pytorch si no tengo un GPU nvida?\n",
    "\n",
    "Para este curso si, esto debido a que pytorch tiene un implementación robusta para la construcción de diferentes arquitecturas de redes neuronales, tiene una variedad de método de entrenamiento y en general facilita el manejo de  una red neuronal.\n",
    "\n",
    "Nota: En caso de no tener un GPU Nvidia el programa simplemente se ejecutara en nuestro CPU\n",
    "\n",
    "\n",
    "## Tensor\n",
    "\n",
    "Un tensor es la estructura mas importante que nos brinda Pytorch. ¿Qué es un tensor?\n",
    "\n",
    "Un tensor lo podemos ver como un arreglo de numpy, de hecho podemos decir que funcionan de similar, con una gran diferencia, los tensores pueden realizar sus operaciones haciendo uso de un la arquitectura CUDA, mientras que las operaciones con arreglos de Numpy generalemnte se realizan en nuestro CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.0297e-16, 4.5839e-41, 6.0297e-16, 4.5839e-41],\n",
      "        [4.4842e-44, 0.0000e+00, 1.5695e-43, 0.0000e+00]])\n",
      "Tensor usando rand()\n",
      "tensor([[0.8151, 0.3719, 0.4234, 0.4354],\n",
      "        [0.2480, 0.3946, 0.6242, 0.3195]])\n",
      "Tensor usando zeros()\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Tensor usando una lista\n",
      "tensor([3.1400, 2.7500])\n",
      "Tamaño\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Importamos el paquete de pytorch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Inicializacion de un tensor\n",
    "\n",
    "#Para inicia un tensor tenemos una amplia variedad de comandos, en el siguiente ejemplo creamos un tensor\n",
    "#  de dimension 2X4\n",
    "\n",
    "x = torch.empty(2, 4)\n",
    "print(x)\n",
    "\n",
    "#En en el ejemplo anterior simplemente estamos declarando que x es un tensor de dimension 2x4, pero el tensor\n",
    "#no ha sido inicializado, en este caso pytorch simplemente imprime los valores que se encuentran en la memoria\n",
    "\n",
    "# Para crear un tensor de dimension 2x4 con valores aleatorios\n",
    "x = torch.rand(2, 4)\n",
    "print(\"Tensor usando rand()\")\n",
    "print(x)\n",
    "\n",
    "\n",
    "# Creamos un tensor de puros ceros, donde cada entrada es de tipo número punto flotante\n",
    "x = torch.zeros(2, 4, dtype=torch.float)\n",
    "print(\"Tensor usando zeros()\")\n",
    "print(x)\n",
    "\n",
    "#Nota: Por lo general los metodos que conocen para crear arreglos de numpy, tienen un homonimo en pytorch\n",
    "\n",
    "#Tambien podemos crear tensores a partir de listas\n",
    "\n",
    "x = torch.tensor([3.14, 2.75])\n",
    "print(\"Tensor usando una lista\")\n",
    "print(x)\n",
    "\n",
    "#Para obtener las dimensiones de nuestro tensor\n",
    "print(\"Tamaño\")\n",
    "print(x.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4747, 0.6403, 0.1310],\n",
      "        [0.4027, 0.7530, 0.3021],\n",
      "        [0.8889, 0.5031, 0.5241],\n",
      "        [0.2573, 0.4944, 0.0839],\n",
      "        [0.8437, 0.6687, 0.2242],\n",
      "        [0.0506, 0.1619, 0.9607]])\n",
      "Sumar escalar 5\n",
      "tensor([[5.4747, 5.6403, 5.1310],\n",
      "        [5.4027, 5.7530, 5.3021],\n",
      "        [5.8889, 5.5031, 5.5241],\n",
      "        [5.2573, 5.4944, 5.0839],\n",
      "        [5.8437, 5.6687, 5.2242],\n",
      "        [5.0506, 5.1619, 5.9607]])\n",
      "Restar escalar 5\n",
      "tensor([[-4.5253, -4.3597, -4.8690],\n",
      "        [-4.5973, -4.2470, -4.6979],\n",
      "        [-4.1111, -4.4969, -4.4759],\n",
      "        [-4.7427, -4.5056, -4.9161],\n",
      "        [-4.1563, -4.3313, -4.7758],\n",
      "        [-4.9494, -4.8381, -4.0393]])\n",
      "multiplicar escalar 5\n",
      "tensor([[2.3733, 3.2017, 0.6552],\n",
      "        [2.0135, 3.7650, 1.5107],\n",
      "        [4.4443, 2.5156, 2.6206],\n",
      "        [1.2867, 2.4718, 0.4194],\n",
      "        [4.2184, 3.3436, 1.1209],\n",
      "        [0.2530, 0.8094, 4.8036]])\n",
      "Dividir escalar 5\n",
      "tensor([[0.0949, 0.1281, 0.0262],\n",
      "        [0.0805, 0.1506, 0.0604],\n",
      "        [0.1778, 0.1006, 0.1048],\n",
      "        [0.0515, 0.0989, 0.0168],\n",
      "        [0.1687, 0.1337, 0.0448],\n",
      "        [0.0101, 0.0324, 0.1921]])\n",
      "\n",
      "Operacion entre dos tensores\n",
      "tensor([[0.2424, 0.7120, 0.7127],\n",
      "        [0.0889, 0.4335, 0.1899],\n",
      "        [0.1868, 0.6885, 0.0178],\n",
      "        [0.1261, 0.4785, 0.8685],\n",
      "        [0.9583, 0.3534, 0.7174],\n",
      "        [0.9358, 0.9872, 0.0819]])\n",
      "Sumar5\n",
      "tensor([[0.7170, 1.3524, 0.8437],\n",
      "        [0.4916, 1.1865, 0.4921],\n",
      "        [1.0757, 1.1916, 0.5419],\n",
      "        [0.3835, 0.9728, 0.9524],\n",
      "        [1.8020, 1.0221, 0.9416],\n",
      "        [0.9864, 1.1491, 1.0426]])\n",
      "Restar\n",
      "tensor([[ 0.2323, -0.0717, -0.5816],\n",
      "        [ 0.3138,  0.3195,  0.1122],\n",
      "        [ 0.7020, -0.1854,  0.5063],\n",
      "        [ 0.1312,  0.0159, -0.7846],\n",
      "        [-0.1146,  0.3154, -0.4932],\n",
      "        [-0.8852, -0.8253,  0.8788]])\n",
      "multiplicar\n",
      "tensor([[0.1150, 0.4559, 0.0934],\n",
      "        [0.0358, 0.3264, 0.0574],\n",
      "        [0.1661, 0.3464, 0.0093],\n",
      "        [0.0325, 0.2365, 0.0728],\n",
      "        [0.8085, 0.2363, 0.1608],\n",
      "        [0.0473, 0.1598, 0.0787]])\n",
      "Dividir\n",
      "tensor([[ 1.9584,  0.8994,  0.1839],\n",
      "        [ 4.5313,  1.7371,  1.5908],\n",
      "        [ 4.7575,  0.7307, 29.4367],\n",
      "        [ 2.0406,  1.0332,  0.0966],\n",
      "        [ 0.8804,  1.8925,  0.3125],\n",
      "        [ 0.0541,  0.1640, 11.7345]])\n"
     ]
    }
   ],
   "source": [
    "#En cuanto operaciones basicas aritmeticas de tensores funcionan igual que las operaciones de arreglos de numpy\n",
    "\n",
    "x=torch.rand((6,3))\n",
    "print(x)\n",
    "\n",
    "#Sumamos,restar,multiplicar,dividir un escalar a todos los valores de nuetro tensor\n",
    "\n",
    "print(\"Sumar escalar 5\")\n",
    "print(x + 5)\n",
    "\n",
    "print(\"Restar escalar 5\")\n",
    "print(x - 5)\n",
    "\n",
    "\n",
    "print(\"multiplicar escalar 5\")\n",
    "print(x * 5)\n",
    "\n",
    "\n",
    "print(\"Dividir escalar 5\")\n",
    "print(x / 5)\n",
    "\n",
    "\n",
    "# De la misma forma las operaciones entre dos tensores entrada por entrada\n",
    "\n",
    "print(\"\\nOperacion entre dos tensores\")\n",
    "y = torch.rand((6,3))\n",
    "print(y)\n",
    "\n",
    "print(\"Sumar5\")\n",
    "print(x + y)\n",
    "\n",
    "print(\"Restar\")\n",
    "print(x - y)\n",
    "\n",
    "\n",
    "print(\"multiplicar\")\n",
    "print(x * y)\n",
    "\n",
    "\n",
    "print(\"Dividir\")\n",
    "print(x / y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que en los ejemplos anteriores el tensor x nunca es modificado, es decir, operaciones tipo x + 5 nos regresan un nuevo tensor resultado de esa operacion, dejando intacto al tensor x.\n",
    "\n",
    "Si queremos modificar directamente x, se puede recurrir a llamar a las funciones correpondientes a las operaciones con un _ al final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original x\n",
      "tensor([[0.4747, 0.6403, 0.1310],\n",
      "        [0.4027, 0.7530, 0.3021],\n",
      "        [0.8889, 0.5031, 0.5241],\n",
      "        [0.2573, 0.4944, 0.0839],\n",
      "        [0.8437, 0.6687, 0.2242],\n",
      "        [0.0506, 0.1619, 0.9607]])\n",
      "\n",
      "Sumanos 5\n",
      "tensor([[5.4747, 5.6403, 5.1310],\n",
      "        [5.4027, 5.7530, 5.3021],\n",
      "        [5.8889, 5.5031, 5.5241],\n",
      "        [5.2573, 5.4944, 5.0839],\n",
      "        [5.8437, 5.6687, 5.2242],\n",
      "        [5.0506, 5.1619, 5.9607]])\n",
      "\n",
      " Restamos 5\n",
      "tensor([[0.4747, 0.6403, 0.1310],\n",
      "        [0.4027, 0.7530, 0.3021],\n",
      "        [0.8889, 0.5031, 0.5241],\n",
      "        [0.2573, 0.4944, 0.0839],\n",
      "        [0.8437, 0.6687, 0.2242],\n",
      "        [0.0506, 0.1619, 0.9607]])\n",
      "\n",
      "Sumanos tensor y\n",
      "tensor([[0.7170, 1.3524, 0.8437],\n",
      "        [0.4916, 1.1865, 0.4921],\n",
      "        [1.0757, 1.1916, 0.5419],\n",
      "        [0.3835, 0.9728, 0.9524],\n",
      "        [1.8020, 1.0221, 0.9416],\n",
      "        [0.9864, 1.1491, 1.0426]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor original x\")\n",
    "print(x)\n",
    "print(\"\\nSumanos 5\")\n",
    "x.add_(5)\n",
    "print(x)\n",
    "\n",
    "print(\"\\n Restamos 5\")\n",
    "x.add_(-5)\n",
    "print(x)\n",
    "\n",
    "print(\"\\nSumanos tensor y\")\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor y Numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra facilidad que nos brinda tenserflow es la facilidad para pasar un arreglo de numpy a un tensor y para pasar\n",
    "un tensor a un arreglo de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "\n",
      "Arreglo numpy\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Arreglo numpy\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Tensor\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Pasamos un tensor a un arreglo de numpy\n",
    "\n",
    "\n",
    "x = torch.ones((12,4))\n",
    "print(\"Tensor\")\n",
    "print(x)\n",
    "\n",
    "print(\"\\nArreglo numpy\")\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "\n",
    "\n",
    "# Arreglo de numpy a tensor\n",
    "x = np.ones((8,4))\n",
    "print(\"\\nArreglo numpy\")\n",
    "print(x)\n",
    "\n",
    "\n",
    "y = torch.from_numpy(x)\n",
    "print(\"\\nTensor\")\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo importante que debemos notar de este método es que cualquier modificación que realizan al tensor orginal o\n",
    "al arreglo original de numpy, tambien afectara al arreglo o tensor correspondiente. Esto solo sucede cuando se \n",
    "esta usando el CPU para realizar las operaciones y no un GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arreglo numpy \n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "Tensor correspondiente\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n",
      "\n",
      "Sumamos el escalar 5 al arreglo de numpy\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "\n",
      "Los cambios también se efectuan de forma automatica en nuestro tensor asociado\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nArreglo numpy \")\n",
    "print(x)\n",
    "\n",
    "print(\"\\nTensor correspondiente\")\n",
    "print(y)\n",
    "\n",
    "print(\"\\nSumamos el escalar 5 al arreglo de numpy\")\n",
    "np.add(x, 1, out=x)\n",
    "print(x)\n",
    "\n",
    "print(\"\\nLos cambios también se efectuan de forma automatica en nuestro tensor asociado\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}