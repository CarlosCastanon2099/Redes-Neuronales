{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal de tres capas con regularización\n",
    "\n",
    "Los datos utilizados para ejercicio se pueden descargar de:\n",
    "https://www.kaggle.com/datasets/hojjatk/mnist-dataset\n",
    "\n",
    "Descarga los cuatro archivos.\n",
    "\n",
    "Los archivos descomprimidos deberán de colocarse en la carpeta /mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import json, matplotlib\n",
    "s = json.load( open(\"styles/bmh_matplotlibrc.json\") )\n",
    "matplotlib.rcParams.update(s)\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 5)\n",
    "colores = [\"#348ABD\", \"#A60628\",\"#06A628\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from perceptron import RedMulticapa, makeX, makeY, logistica, derLogistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "Los datos a utilizar son imágenes de dígitos.  En su formato original, se leen dos vectores:\n",
    "* Los datos de **entrada** vienen en un vector 3D.\n",
    "  * Cada renglón corresponde a un ejemplar de entrenamiento.\n",
    "  * En cada renglón hay una matriz 2D con las intensidades de los pixels.\n",
    "* Las etiquetas (dígito correcto que representan) vienen en un vector de una dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mnist.read import read, printFull\n",
    "\n",
    "filesDir = './mnist/'\n",
    "trainingSetFile = filesDir + 'train-images-idx3-ubyte'\n",
    "trainingSetLabelsFile = filesDir + 'train-labels-idx1-ubyte'\n",
    "testSetFile = filesDir + 't10k-images-idx3-ubyte'\n",
    "testSetLabelsFile = filesDir + 't10k-labels-idx1-ubyte'\n",
    "\n",
    "###     /\\ |__   __||  ____|| \\ | | / ____||_   _|/ __ \\ | \\ | |\n",
    "###    /  \\   | |   | |__   |  \\| || |       | | | |  | ||  \\| |\n",
    "###   / /\\ \\  | |   |  __|  | . ` || |       | | | |  | || . ` |\n",
    "###  / ____ \\ | |   | |____ | |\\  || |____  _| |_| |__| || |\\  |\n",
    "### /_/    \\_\\|_|   |______||_| \\_| \\_____||_____|\\____/ |_| \\_|\n",
    "### EN LAS SIQUIENTES DOS LINEAS SE LIMITA EL TAMAÑO DE LOS DATOS DE ENTRENAMIENTO,EN CASO\n",
    "### DE INCREMENTAR LA CANTIDAD EL CALCULO TOMA DRASTICAMENTE MAS TIEMPO EN EL CASO DE APROXIMACION DEL GRADIENTE,SE INCLUYE\n",
    "### IMPRESION DEL PROGRESO DEL METODO\n",
    "\n",
    "\n",
    "\n",
    "trainData = read(fileName=trainingSetFile).astype(np.float64)\n",
    "trainDataLabels = read(fileName=trainingSetLabelsFile).astype(np.float64)\n",
    "\n",
    "testData = read(fileName=testSetFile).astype(np.float64)\n",
    "testDataLabels = read(fileName=testSetLabelsFile).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist.plot\n",
    "from mnist.plot import muestraImagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los datos para que estén entre 0 y 1\n",
    "\n",
    "trainData=trainData/255\n",
    "testData=testData/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Función para ver como son los datos de MNIST\n",
    "\n",
    "@interact(\n",
    "    indice = (0, len(trainData) - 1)\n",
    ")\n",
    "def muestraImagenEntrenamiento(indice):\n",
    "    muestraImagen(trainData, trainDataLabels, indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder trabajar con la red neuronal, necesitaremos transformar esas entradas, de modo que los valores de las intensidades de los pixeles se encuentren en un solo renglón.  Las entradas a la red neuronal, deberán ser de la forma:\n",
    "\\begin{align}\n",
    "  X &= \\begin{bmatrix}\n",
    "       x_1^{(1)} ... x_n^{(1)}  \\\\\n",
    "       x_1^{(2)} ... x_n^{(2)}  \\\\\n",
    "       ...\\\\\n",
    "       x_1^{(m)} ... x_n^{(m)}\n",
    "      \\end{bmatrix}\n",
    "\\end{align}\n",
    "También necesitaremos que las etiquetas formen una matriz donde la única columna distinta de cero, sea la correspondiente al dígito correcto:\n",
    "\\begin{align}\n",
    "  Y &= \\begin{bmatrix}\n",
    "       0, ..., y_{label_0} = 1 , ... ,0 \\\\\n",
    "       ... \\\\\n",
    "       0, ..., y_{label_n} = 1 , ... ,0 \\\\\n",
    "      \\end{bmatrix}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define las matrices X y Y, como se muestra arriba\n",
    "## A partir de trainData y trainDataLabels\n",
    "## TIP: usar reshape\n",
    "def makeX(datosEntrenamiento):\n",
    "    pass\n",
    "\n",
    "def makeY(etiquetasEntrenamiento):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = makeX(trainData)\n",
    "print(\"X shape=\",X.shape)\n",
    "Y = makeY(trainDataLabels)\n",
    "print(\"Y shape=\",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repite lo mismo con los datos de validación\n",
    "XTest = makeX(testData)\n",
    "YTest = makeY(testDataLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red con tres capas\n",
    "La red neuronal que se utilizará es una red neuronal de tres capas:\n",
    "* Entrada\n",
    "* Oculta\n",
    "* Salida\n",
    "La forma genérica de la red se ilustra a continuación.  Sólo que la red de este ejercicio tendrá más neuronas en cada capa.\n",
    "<img src=\"figuras/Red3Capas.png\"/>\n",
    "\n",
    "Para este ejercicio el número de neuronas será:\n",
    "* 784 + 1 (28x28 pixeles más la unidad de sesgo)\n",
    "* 25 + 1 unidades en la capa oculta\n",
    "* 10 neuronas de salida (una por cada dígito)\n",
    "Por lo tanto, las dimensiones de las matrices de pesos son:\n",
    "* $\\Theta^{(0)} \\rightarrow (25 \\times 785)$\n",
    "* $\\Theta^{(1)} \\rightarrow (10 \\times 26)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "Se buscará mantener los pesos pequeños para evitar los debordes y el sobreajuste a los datos\n",
    "de entrenamiento.  Para ello, la función $J$, además de medir el error en la predicción, será\n",
    "incrementada cuando los pesos incrementen su magnitud.\n",
    "\\begin{align}\n",
    "  J(\\Theta) =& - \\frac{1}{m} \\left[ \\sum_{i=1}^m \\sum_{k=1}^K   y_k^{(i)} \\log(h_\\Theta(x^{(i)}))_k  +\n",
    "            (1 - y_k^{(i)}) \\log(1 - h_\\Theta(x^{(i)}))_k   \\right]    + \\\\\n",
    "            & \\frac{\\lambda}{2m} \\sum_{l=1}^{L-1} \\sum_{i=1}^{s_L} \\sum_{j=1}^{s_{l+1}} (\\theta_{ji}^{(l)})^2\n",
    "\\end{align}\n",
    "De este modo, al calcular el gradiente se hace la siguiente modificación:\n",
    "\\begin{align}\n",
    " \\nabla^{(l)} =& \\frac{1}{m}\\Delta^{(l)} \\\\\n",
    " \\nabla^{(l)}[:,1:] =& \\nabla^{(l)}[:,1:] + \\frac{\\lambda}{m} \\Theta^{(l)}[:,1:]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta red tiene\n",
    "print(25*785 + 10*26, ' conexiones.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistica(val):\n",
    "    return 1/(1+np.exp(-val))\n",
    "\n",
    "def derLogistica(val):\n",
    "    return logistica(val) * (1 - logistica(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa una clase RedNeuronal con la arquitectura anterior y que tome en cuenta la regularización.\n",
    "## Puedes usar como base la red definida en la práctica anterior.\n",
    "## Debe tener:\n",
    "## - como *atributos* las matrices de pesos Theta_0 y Theta_1\n",
    "## - un *constructor* que reciba como parámetro opcional otra red y copie sus pesos,\n",
    "##   si no recibe nada los inicializa aleatoriamente.\n",
    "## - método para asignar valores aleatorios a estas matrices\n",
    "## - método para devolver todos los pesos en una sola matriz columna.\n",
    "## - metodo para reconstruir matrices del tamaño de las matrices de pesos, a partir del vector.\n",
    "## Define una función de entrenamiento para la red.\n",
    "\n",
    "# Cuando agregues el término de la regularización, recuerda hacer los cambios\n",
    "# únicamente sobre las componentes que no corresponden al bias.\n",
    "# Puedes utilizar notación como:\n",
    "# M[:,1:] = f(M[:,1:])\n",
    "# donde f(x) es una función cualquiera que depende de x.\n",
    "\n",
    "class RedMulticapa:\n",
    "    def __init__(self,otra=None):\n",
    "    \n",
    "    def pesos_a_vector(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def reconstruct_matrices(matriz):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa el método *feedforward(self, X, vector=None)*\n",
    "## Cuando reciba vector, usará estos pesos, en lugar de los propios.\n",
    "##\n",
    "def feed_forward(self,X,vector=None):\n",
    "    pass\n",
    "setattr(RedMulticapa,'feed_forward',feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mnist.plot)\n",
    "\n",
    "from mnist.plot import muestraActividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RedA = RedMulticapa()\n",
    "RedA.feed_forward(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto sólo es ilustrativo, por eso usamos el conjunto de prueba,\n",
    "# que es más pequeño\n",
    "\n",
    "@interact(index = (0, len(XTest) - 1))\n",
    "def muestraActividad0(index):\n",
    "    muestraActividad(RedA, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa un método para calcular el error.\n",
    "## Usar la entropía cruzada.\n",
    "## Recuerda dar la opción de enviar un vector de pesos modificados.\n",
    "def calc_error(self,xtest,ytest,pesos,lambdaR):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "setattr(RedMulticapa,'calc_error',calc_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RedB = RedMulticapa(RedA)\n",
    "RedB.calc_error(XTest, YTest, RedB.pesos_a_vector())#, lambdaR = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa el método *aproximaGradiente(self, X, Y, lambdaR = 0.0)*\n",
    "## Esta función perturbará los pesos uno a uno, por una cantidad\n",
    "## epsilon = 0.0004 y devolverá un vector con el gradiente.\n",
    "def approx_gradient(self, X, Y):\n",
    "    pass\n",
    "\n",
    "setattr(RedMulticapa,'approx_gradient',approx_gradient)\n",
    "aprox = RedB.approx_gradient(X[0:1,:], YTest[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Programa el algoritmo de propagación hacia atrás\n",
    "## de modo que reciba X, Y y lambda=0.0\n",
    "## Guardará como atributos los valores calculados\n",
    "## para el error y los gradientes de las matrices de pesos\n",
    "def back_propagate(self,x,y,lambdaR=0.0):\n",
    "    pass\n",
    "\n",
    "setattr(RedMulticapa,'back_propagate',back_propagate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agrega ahora el método para realizar descenso por el gradiente\n",
    "def gradient_descent(self,X,Y,alfa,ciclos,lambdaR=0.0):\n",
    "    pass\n",
    "setattr(RedMulticapa,'gradient_descent',gradient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tendrás que correr el entrenamiento varias veces para que el sistema funcione.\n",
    "# Toma en cuenta que X es una matriz bastante grande, por lo que será un poco tardado.\n",
    "# Observa que aparecerán advertencias de que el cálculo de la exponencial en la\n",
    "# función de evaluación está desbordando.\n",
    "# No olvides revisar tus metádatos, prueba entrenamiento con diferentes lambdaR. \n",
    "\n",
    "@interact_manual()\n",
    "def entrenaRedC():\n",
    "    RedB.gradient_descent(X, Y, alfa=0.1, ciclos = 10, lambdaR=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ya funciona bien tu entrenamiento, corre algunos ciclos más para reducir el error\n",
    "# más significativamente.\n",
    "\n",
    "@interact(index = (0, len(X) - 1))\n",
    "def muestraActividad0(index):\n",
    "    muestraActividad(RedB, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión\n",
    "Calcula los valores de la matriz de confusión para evaluar el desempeño de tu red después de haberla entrenado.\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr><th colspan=\"2\"></th><th colspan=\"2\">Clase predicha</th></tr>\n",
    "<tr><th colspan=\"2\"></th><th>1</th><th>0</th></tr>\n",
    "</thead>\n",
    "<tr><th rowspan=\"2\">Clase correcta</th><th>1</th><td>TP</td><td>FN</td></tr>\n",
    "<tr><th>0</th><td>FP</td><td>TN</td></tr>\n",
    "</table>\n",
    "\n",
    "Donde:\n",
    "* **TP**: Verdaderos positvos, valores que se evaluaron como verdaderos y eran verdaderos.\n",
    "* **FP**: Falsos posivos, valores que se evaluaron como verdaderos pero eran errados. \n",
    "* **FN**: Falsos negativos, valores evaluados como falsos pero debian ser verdaderos.\n",
    "* **TN**: Verdaderos negativos, valores evaluados como falsos y eran falsos.\n",
    "\n",
    "En nuestro ejercicio debemos ver en los valores resultantes, para cada ejemplar tenemos 10 elementos de salida, \n",
    "si en el vector de salida se activa la posición correspondiente a la etiqueta. Por ejemplo, si la salida es de la forma $[0,1,0,0,0,0,0,0,0,0]$ y la etiqueta es un 1 entonces tienes un verdadero positivo por el 1 y 9 verdaderos negativos por todos los que no se activaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inserta aquí el código para calcular la matriz de confusión\n",
    "def matrizDeConfusion(self,Y):\n",
    "    pass\n",
    "\n",
    "setattr(RedMulticapa,'confusion',matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RedB.matrizDeConfusion(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read() #or edit path to custom.css\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
